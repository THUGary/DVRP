from __future__ import annotations
import argparse
import os
import time
from typing import Tuple, List, Dict, Any

import torch
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

from models.planner_model.model import DVRPNet  # 需与现有模型实现一致


class PlanRowsDataset(Dataset):
    """读取 data_gen.py 生成的 rows 格式数据"""
    def __init__(self, path: str):
        super().__init__()
        blob = torch.load(path, map_location="cpu")
        self.rows: List[Dict[str, Any]] = blob["rows"]
        self.meta: Dict[str, Any] = blob.get("meta", {})

    def __len__(self) -> int:
        return len(self.rows)

    def __getitem__(self, idx: int) -> Dict[str, Any]:
        return self.rows[idx]


def collate_rows(batch: List[Dict[str, Any]]) -> Dict[str, torch.Tensor]:
    """将变长 nodes 的 row 批量化"""
    B = len(batch)
    maxN = max((len(item["nodes"]) for item in batch), default=0)

    nodes = torch.zeros(B, maxN, 5, dtype=torch.float32)
    node_mask = torch.ones(B, maxN, dtype=torch.bool)  # 先全 True，后面有效部分按 row.mask
    agents = torch.zeros(B, 1, 4, dtype=torch.float32)
    depot = torch.zeros(B, 1, 3, dtype=torch.float32)
    labels = torch.zeros(B, dtype=torch.long)
    valid_N = torch.zeros(B, dtype=torch.long)

    for b, item in enumerate(batch):
        Ni = len(item["nodes"])
        valid_N[b] = Ni
        if Ni > 0:
            nodes[b, :Ni] = torch.tensor(item["nodes"], dtype=torch.float32)
            if "node_mask" in item:
                mask_i = torch.tensor(item["node_mask"], dtype=torch.bool)
            else:
                mask_i = torch.zeros(Ni, dtype=torch.bool)
            node_mask[b, :Ni] = mask_i
        ax, ay, s, ta = item["agent"]
        agents[b, 0] = torch.tensor([ax, ay, s, ta], dtype=torch.float32)
        dx, dy, td = item["depot"]
        depot[b, 0] = torch.tensor([dx, dy, td], dtype=torch.float32)
        labels[b] = int(item["label"])

    return {
        "nodes": nodes,
        "node_mask": node_mask,
        "agents": agents,
        "depot": depot,
        "labels": labels,
        "valid_N": valid_N,
    }


def build_argparser() -> argparse.ArgumentParser:
    p = argparse.ArgumentParser(description="Train DVRPNet on rows generated by data_gen.py")
    # data
    p.add_argument("--data_dir", type=str, default="data")
    p.add_argument("--map_wid", type=int, default=20)
    p.add_argument("--agent_num", type=int, default=2)
    p.add_argument("--prefix", type=str, default="plans")
    # model
    p.add_argument("--d_model", type=int, default=128)
    p.add_argument("--nhead", type=int, default=8)
    p.add_argument("--nlayers", type=int, default=2)
    p.add_argument("--lateness_lambda", type=float, default=0.0)
    # train
    p.add_argument("--epochs", type=int, default=200)
    p.add_argument("--batch_size", type=int, default=256)
    p.add_argument("--lr", type=float, default=1e-3)
    p.add_argument("--weight_decay", type=float, default=1e-6)
    p.add_argument("--num_workers", type=int, default=4)
    p.add_argument("--device", type=str, default="cuda", choices=["cuda", "cpu"])
    p.add_argument("--amp", action="store_true")
    p.add_argument("--seed", type=int, default=42)
    p.add_argument("--ckpt_dir", type=str, default="checkpoints")
    return p


def save_ckpt(model: DVRPNet, ckpt_dir: str, map_wid: int, agent_num: int, epoch: int) -> str:
    os.makedirs(ckpt_dir, exist_ok=True)
    name = f"planner_{map_wid}_{agent_num}_{epoch}.pt"
    path = os.path.join(ckpt_dir, name)
    torch.save({"model": model.state_dict()}, path)
    print(f"[CKPT] saved => {path}")
    return path


@torch.no_grad()
def evaluate(model: DVRPNet, loader: DataLoader, device: torch.device, lateness_lambda: float, amp: bool) -> Tuple[float, float]:
    model.eval()
    total_loss, total_cnt, total_corr = 0.0, 0, 0
    for batch in loader:
        nodes = batch["nodes"].to(device)
        node_mask = batch["node_mask"].to(device)
        agents = batch["agents"].to(device)
        depot = batch["depot"].to(device)
        labels = batch["labels"].to(device)
        valid_N = batch["valid_N"].to(device)

        with torch.cuda.amp.autocast(enabled=amp):
            feats = {"nodes": nodes, "node_mask": node_mask, "agents": agents, "depot": depot}
            # 注意：若模型支持基于当前时间修正，可将 agents[...,3] 传入 current_time
            current_time = 0.0
            logits = DVRPNet.decode_step(model, feats, lateness_lambda=lateness_lambda, current_time=current_time)  # [B,Nmax+1]

            B, Np1 = logits.shape
            Nmax = Np1 - 1
            range_ids = torch.arange(Nmax, device=device).unsqueeze(0).expand(B, -1)
            pad_mask = range_ids >= valid_N.unsqueeze(1)   # [B,Nmax]
            eff_mask = torch.logical_or(node_mask, pad_mask)
            full_mask = torch.cat([eff_mask, torch.zeros(B, 1, dtype=torch.bool, device=device)], dim=1)
            logits = logits.masked_fill(full_mask, float("-inf"))

            loss = F.cross_entropy(logits, labels)
            pred = torch.argmax(logits, dim=-1)
            total_loss += loss.item() * labels.size(0)
            total_cnt += labels.size(0)
            total_corr += (pred == labels).sum().item()
    return total_loss / max(1, total_cnt), total_corr / max(1, total_cnt)


def main():
    args = build_argparser().parse_args()
    torch.manual_seed(args.seed)
    device = torch.device("cuda" if (args.device == "cuda" and torch.cuda.is_available()) else "cpu")

    # 数据路径
    train_path = os.path.join(args.data_dir, f"{args.prefix}_train_{args.map_wid}_{args.agent_num}.pt")
    val_path = os.path.join(args.data_dir, f"{args.prefix}_val_{args.map_wid}_{args.agent_num}.pt")
    if not (os.path.exists(train_path) and os.path.exists(val_path)):
        raise FileNotFoundError(f"Missing data files: {train_path} or {val_path}. Run data_gen.py first.")

    # Dataset / Loader
    trn_ds = PlanRowsDataset(train_path)
    val_ds = PlanRowsDataset(val_path)
    train_loader = DataLoader(trn_ds, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers, pin_memory=True, collate_fn=collate_rows)
    val_loader = DataLoader(val_ds, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers, pin_memory=True, collate_fn=collate_rows)

    # 模型/优化
    model = DVRPNet(d_model=args.d_model, nhead=args.nhead, nlayers=args.nlayers).to(device)
    opt = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)
    scaler = torch.cuda.amp.GradScaler(enabled=args.amp)

    last_ckpt = None
    try:
        for epoch in range(1, args.epochs + 1):
            model.train()
            t0 = time.time()
            for batch in train_loader:
                nodes = batch["nodes"].to(device)
                node_mask = batch["node_mask"].to(device)
                agents = batch["agents"].to(device)
                depot = batch["depot"].to(device)
                labels = batch["labels"].to(device)
                valid_N = batch["valid_N"].to(device)

                with torch.cuda.amp.autocast(enabled=args.amp):
                    feats = {"nodes": nodes, "node_mask": node_mask, "agents": agents, "depot": depot}
                    current_time = 0.0
                    logits = DVRPNet.decode_step(model, feats, lateness_lambda=args.lateness_lambda, current_time=current_time)

                    B, Np1 = logits.shape
                    Nmax = Np1 - 1
                    range_ids = torch.arange(Nmax, device=device).unsqueeze(0).expand(B, -1)
                    pad_mask = range_ids >= valid_N.unsqueeze(1)
                    eff_mask = torch.logical_or(node_mask, pad_mask)
                    full_mask = torch.cat([eff_mask, torch.zeros(B, 1, dtype=torch.bool, device=device)], dim=1)
                    logits = logits.masked_fill(full_mask, float("-inf"))

                    loss = F.cross_entropy(logits, labels)

                opt.zero_grad(set_to_none=True)
                scaler.scale(loss).backward()
                scaler.step(opt)
                scaler.update()

            # 评价与保存
            val_loss, val_acc = evaluate(model, val_loader, device, args.lateness_lambda, args.amp)
            dt = time.time() - t0
            print(f"[Epoch {epoch:03d}] train_loss={loss.item():.4f} | val_loss={val_loss:.4f} | val_acc={val_acc:.4f} | {dt:.1f}s")

            if epoch % 50 == 0:
                last_ckpt = save_ckpt(model, args.ckpt_dir, args.map_wid, args.agent_num, epoch)

    except KeyboardInterrupt:
        print("[INTERRUPTED] saving checkpoint...")
        last_epoch = epoch if 'epoch' in locals() else 0
        last_ckpt = save_ckpt(model, args.ckpt_dir, args.map_wid, args.agent_num, last_epoch)
        return
    finally:
        last_epoch = epoch if 'epoch' in locals() else args.epochs
        last_ckpt = save_ckpt(model, args.ckpt_dir, args.map_wid, args.agent_num, last_epoch)


if __name__ == "__main__":
    main()